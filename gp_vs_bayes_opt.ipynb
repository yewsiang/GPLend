{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data import load_dataset, get_train_test_split\n",
    "from optimization import gp_optimize_threshold\n",
    "from evaluation import train_and_test_other_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dataset/LoanStats3a.csv\"\n",
    "features, data = load_dataset(filename)\n",
    "print(\"Data shape: %s\" % str(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENT 1: GP VS BAYES OPT IN LATER STAGES\n",
    "-------------------------------------------------------\n",
    "Set up:\n",
    "1. Get 100-500 data rows to as training set.\n",
    "2. Create a GP model and train it with training set.\n",
    "3. Let K = 100-200.\n",
    "Experiment:\n",
    "1. Let GP_model do prediction and self-updating using loan_amount_and_variance version for K more steps. Then pure prediction.\n",
    "2. Let GP_model do prediction and self-updating using Bayesian optimization for K more steps. Then pure prediction.\n",
    "3. [OPTIONAL] Let SVM do prediction after training with training set to compare.\n",
    "Results:\n",
    "1. Compare the 3 profits gained at the end of all periods.\n",
    "\"\"\"\n",
    "\n",
    "# Get train test split. Ratio is train:test = 1:9 since Bayesian Optimization is used for this\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(features, test_size=0.9, random_state=0)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Temporarily use subset of data to debug faster\n",
    "# TODO: Remove\n",
    "# X_train, y_train = X_train[:100,:], y_train[:100]\n",
    "# X_val, y_val     = X_val[:500,:], y_val[:500]\n",
    "# X_test, y_test   = X_test[:500,:], y_test[:500]\n",
    "\n",
    "# Normalize\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train = X_scaler.transform(X_train)\n",
    "# X_val = X_scaler.transform(X_val)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train: %s, y_train: %s\" % (str(X_train.shape), str(y_train.shape)))\n",
    "print(\"X_test: %s, y_test: %s\" % (str(X_test.shape), str(y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Process\n",
    "import GPy\n",
    "\n",
    "# Normalize\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(y_train.reshape(-1,1))\n",
    "y_train_scaled = y_scaler.transform(y_train.reshape(-1,1))\n",
    "\n",
    "# Initialize GP Model\n",
    "kernel = GPy.kern.RBF(input_dim=X_train.shape[1], variance=1., lengthscale=1.)\n",
    "gp_model = GPy.models.GPRegression(X_train, y_train_scaled, kernel)\n",
    "gp_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "SEED            = 1\n",
    "THRESHOLD       = 1.1\n",
    "NUM_PERIODS     = 20\n",
    "NUM_MONTHS      = 60\n",
    "FUND_GIVEN      = 1e6\n",
    "LOANS_PER_MONTH = 100\n",
    "CONF_QUANTILE   = (40,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perf_gp = simulate_N_time_periods(\n",
    "    gp_model,\n",
    "    X_test, y_test,\n",
    "    X_scaler, y_scaler,\n",
    "    threshold=THRESHOLD,\n",
    "    num_periods=NUM_PERIODS,\n",
    "    fund_given=FUND_GIVEN,\n",
    "    num_months=NUM_MONTHS,\n",
    "    incoming_loans_per_time_period=LOANS_PER_MONTH,\n",
    "    conf_quantile=CONF_QUANTILE,\n",
    "    optimize_for=\"TODO\", \n",
    "    version=\"self_updating_gp\",\n",
    "    gp_update_steps=200,\n",
    "    model_type=\"gp\",\n",
    "    seed=SEED\n",
    ")\n",
    "print(\"Profits for self-updating GP:\")\n",
    "print(np.mean(np.sum(perf_gp[:,:,0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "kappa = norm.ppf(0.7)\n",
    "perf_bayes_opt = simulate_N_time_periods(\n",
    "    gp_model,\n",
    "    X_test, y_test,\n",
    "    X_scaler, y_scaler,\n",
    "    threshold=THRESHOLD,\n",
    "    num_periods=NUM_PERIODS,\n",
    "    fund_given=FUND_GIVEN, \n",
    "    num_months=NUM_MONTHS,\n",
    "    incoming_loans_per_time_period=LOANS_PER_MONTH,\n",
    "    conf_quantile=CONF_QUANTILE,\n",
    "    optimize_for=\"TODO\",\n",
    "    version=\"bayesian_optimization\",\n",
    "    kappa=kappa,\n",
    "    bay_opt_steps=200,\n",
    "    model_type=\"gp\", seed=SEED\n",
    ")\n",
    "print(\"Profits for Bayesian Optimization:\")\n",
    "print(np.mean(np.sum(perf_bayes_opt[:,:,0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Total Profits:\")\n",
    "print(np.mean(np.sum(perf_gp[:,:,0], axis=1)))\n",
    "print(np.mean(np.sum(perf_others[:,:,0], axis=1)))\n",
    "print(np.mean(np.sum(perf_bayes_opt[:,:,0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENT 2: GP VS BAYES OPT IN EARLY STAGES\n",
    "-------------------------------------------------------\n",
    "Set up:\n",
    "1. Let K = 100-500.\n",
    "2. Create two GP models: gp_model_normal and gp_model_bayes_opt.\n",
    "3. [OPTIONAL] Create an SVM model.\n",
    "Experiment:\n",
    "1. Train gp_model_normal using K randomly chosen data rows. Then let it do pure prediction.\n",
    "2. Train gp_model_bayes_opt iteratively K steps. Each step explore the row with large acquisition function. Then pure prediction.\n",
    "3. [OPTIONAL] Train svm_model with the same set in step 1 and let it predict to compare.\n",
    "4. [OPTIONAL] Train svm_model with the same set in step 2 and let it predict to compare.\n",
    "Results:\n",
    "1. Compare the 3 profits gained at the end of all periods.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "SEED            = 1\n",
    "THRESHOLD       = 1.1\n",
    "NUM_PERIODS     = 20\n",
    "NUM_MONTHS      = 60\n",
    "FUND_GIVEN      = 1e6\n",
    "LOANS_PER_MONTH = 100\n",
    "CONF_QUANTILE   = (40,100)\n",
    "NUM_TRAIN_ROWS = 100\n",
    "KAPPA = norm.ppf(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data initialization\n",
    "X = features[:,:-2]\n",
    "y = features[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=NUM_TRAIN_ROWS, random_state=0)\n",
    "\n",
    "X_train_bo, X_test_bo, y_train_bo, y_test_bo = train_test_split(X, y, train_size=1, random_state=None)\n",
    "\n",
    "# Normalize X\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "X_train_bo = X_scaler.transform(X_train_bo)\n",
    "X_test_bo = X_scaler.transform(X_test_bo)\n",
    "X = X_scaler.transform(X)\n",
    "\n",
    "# Normalize y\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(y_train.reshape(-1,1))\n",
    "y_train_scaled = y_scaler.transform(y_train.reshape(-1,1))\n",
    "y_train_bo_scaled = y_scaler.transform(y_test_bo.reshape(-1, 1))\n",
    "y = y_scaler.transform()\n",
    "\n",
    "print(\"X_train: %s, y_train: %s\" % (str(X_train.shape), str(y_train.shape)))\n",
    "print(\"X_test: %s, y_test: %s\" % (str(X_test.shape), str(y_test.shape)))\n",
    "print(\"X_train_bo: {}, y_train_bo: {}\".format(X_train_bo.shape, y_train_bo.shape))\n",
    "print(\"X_test_bo: {}, y_test_bo: {}\".format(X_test_bo.shape, y_test_bo.shape))\n",
    "print(\"y_train_scaled: {}\".format(y_train_scaled.shape))\n",
    "print(\"y_train_bo_scaled: {}\".format(y_train_bo_scaled.shape))\n",
    "print(\"X: {}, y: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normal GP model init\n",
    "import GPy\n",
    "kernel = GPy.kern.RBF(input_dim=X_train.shape[1], variance=1., lengthscale=1.)\n",
    "gp_model_normal = GPy.models.GPRegression(X_train, y_train_scaled, kernel)\n",
    "gp_model_normal.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bayesian Optimization GP model init\n",
    "import GPy\n",
    "import numpy as np\n",
    "kernel = GPy.kern.RBF(input_dim=X_train_bo.shape[1], variance=1., lengthscale=1.)\n",
    "gp_model_bay_opt = GPy.models.GPRegression(X_train_bo, y_train_bo_scaled, kernel)\n",
    "gp_model_bay_opt.optimize()\n",
    "\n",
    "for i in range(NUM_TRAIN_ROWS):\n",
    "    mean, var = gp_model_bay_opt.predict(X_test_bo)\n",
    "    acquisition = mean + np.sqrt(var)*KAPPA\n",
    "    next_sample_ind = acquisition.argmax()\n",
    "    next_sample_X = X_test_bo[next_sample_ind].reshape(1,-1)\n",
    "    next_sample_y = y_test_bo[next_sample_ind].reshape(1, -1)\n",
    "    X_train_bo = np.concatenate((X_train_bo, next_sample_X), axis=0)\n",
    "    y_train_bo = np.concatenate((y_train_bo, next_sample_y), axis=0)\n",
    "    X_test_bo = np.delete(X_test_bo, next_sample_ind, axis=0)\n",
    "    y_test_bo = np.delete(y_test_bo, next_sample_ind, axis=0)\n",
    "    gp_model_bay_opt.set_XY(X=X_train_bo, Y=y_train_bo)\n",
    "    gp_model_bay_opt.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Properly init test dataset\n",
    "# TODO TODO TODO TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from simulation import *\n",
    "\n",
    "perf_gp = simulate_N_time_periods(\n",
    "    gp_model_normal,\n",
    "    X_test, y_test,\n",
    "    X_scaler, y_scaler,\n",
    "    threshold=THRESHOLD,\n",
    "    num_periods=NUM_PERIODS,\n",
    "    fund_given=FUND_GIVEN,\n",
    "    num_months=NUM_MONTHS,\n",
    "    incoming_loans_per_time_period=LOANS_PER_MONTH,\n",
    "    conf_quantile=CONF_QUANTILE,\n",
    "    optimize_for=\"TODO\", \n",
    "    version=\"loan_amount_and_variance\",\n",
    "    model_type=\"gp\",\n",
    "    seed=SEED\n",
    ")\n",
    "print(\"Profits for self-updating GP:\")\n",
    "print(np.mean(np.sum(perf_gp[:,:,0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from simulation import *\n",
    "\n",
    "perf_bayes_opt = simulate_N_time_periods(\n",
    "    gp_model_bay_opt,\n",
    "    X_test, y_test,\n",
    "    X_scaler, y_scaler,\n",
    "    threshold=THRESHOLD,\n",
    "    num_periods=NUM_PERIODS,\n",
    "    fund_given=FUND_GIVEN, \n",
    "    num_months=NUM_MONTHS,\n",
    "    incoming_loans_per_time_period=LOANS_PER_MONTH,\n",
    "    conf_quantile=CONF_QUANTILE,\n",
    "    optimize_for=\"TODO\",\n",
    "    version=\"loan_amount_and_variance\",\n",
    "    model_type=\"gp\", seed=SEED\n",
    ")\n",
    "print(\"Profits for Bayesian Optimization:\")\n",
    "print(np.mean(np.sum(perf_bayes_opt[:,:,0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from visualisation import plot_portfolio_performance, plot_portfolio_performance_comparisons\n",
    "# plot_portfolio_performance_comparisons([perf_gp, perf_others, perf_others], legend_names=[\"GP\", \"Others\", \"Others\"])\n",
    "# plot_portfolio_performance(perf_gp)\n",
    "# plot_portfolio_performance(perf_others)\n",
    "# # Optimize threshold for profits / profit_percentage\n",
    "# threshold = gp_optimize_threshold(gp_model, X_val, y_val, X_scaler, y_scaler, optimize_for=\"profit_percentage\")\n",
    "# print(threshold)\n",
    "# train_and_test_other_models(X_train, y_train, X_test, y_test, X_scaler)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
