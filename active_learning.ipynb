{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data import load_dataset, get_train_test_split\n",
    "from evaluation import train_and_test_other_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Feature Engineering...\n",
      "Data shape: (42535, 40)\n"
     ]
    }
   ],
   "source": [
    "filename = \"dataset/LoanStats3a.csv\"\n",
    "features, data = load_dataset(filename)\n",
    "print(\"Data shape: %s\" % str(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (10000, 38), y_train: (10000,)\n",
      "X_val: (5955, 38), y_val: (5955,)\n",
      "X_test: (500, 38), y_test: (500,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(features, test_size=0.3, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Temporarily use subset of data to debug faster\n",
    "# TODO: Remove\n",
    "X_train, y_train = X_train[:10000,:], y_train[:10000]\n",
    "# X_val, y_val     = X_val[:500,:], y_val[:500]\n",
    "X_test, y_test   = X_test[:500,:], y_test[:500]\n",
    "\n",
    "# Normalize\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"X_train: %s, y_train: %s\" % (str(X_train.shape), str(y_train.shape)))\n",
    "print(\"X_val: %s, y_val: %s\" % (str(X_val.shape), str(y_val.shape)))\n",
    "print(\"X_test: %s, y_test: %s\" % (str(X_test.shape), str(y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x7f26d4e2d9b0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from active_learning import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# Normalize\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(y_train.reshape(-1,1))\n",
    "y_train_scaled = y_scaler.transform(y_train.reshape(-1,1))\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=X_train.shape[1], variance=1., lengthscale=1.)\n",
    "import time\n",
    "np.random.seed(int(time.time()))\n",
    "\n",
    "# normal GP\n",
    "# gp_model = GPy.models.SparseGPRegression(X_train_scaled, y_train_scaled, kernel)\n",
    "# gp_model.optimize()\n",
    "\n",
    "# maximum entropy sampling\n",
    "# X_sampled, y_sampled = maximum_entropy_sampling(X_train_scaled, y_train_scaled, 100)\n",
    "# gp_model = GPy.models.GPRegression(X_sampled, y_sampled, kernel)\n",
    "# gp_model.optimize()\n",
    "\n",
    "# DARE sampling\n",
    "# X_sampled, y_sampled = DARE_sampling(X_train_scaled, y_train_scaled, 100, X_scaler) \n",
    "# gp_DARE = GPy.models.GPRegression(X_sampled, y_sampled, kernel)\n",
    "# gp_DARE.optimize()\n",
    "\n",
    "# sum of mean squared error sampling\n",
    "# X_sampled, y_sampled = MSE_sampling(X_train_scaled, y_train_scaled, 100)\n",
    "# gp_model = GPy.models.GPRegression(X_sampled, y_sampled, kernel)\n",
    "# gp_model.optimize()\n",
    "\n",
    "# random sampling\n",
    "# import time\n",
    "# np.random.seed(int(time.time()))\n",
    "X_sampled, y_sampled = random_sampling(X_train_scaled, y_train_scaled, 100)\n",
    "gp_model = GPy.models.GPRegression(X_sampled, y_sampled, kernel)\n",
    "gp_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Simulating period 0...\n",
      "Simulating period 10...\n",
      "Mean Total Profits:\n",
      "361271.152059\n"
     ]
    }
   ],
   "source": [
    "from simulation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "SEED            = int(time.time())\n",
    "THRESHOLD       = 1.1\n",
    "NUM_PERIODS     = 20\n",
    "NUM_MONTHS      = 60\n",
    "FUND_GIVEN      = 1e6\n",
    "LOANS_PER_MONTH = 100\n",
    "CONF_QUANTILE   = (40,100)\n",
    "\n",
    "\n",
    "perf_gp = simulate_N_time_periods(gp_model, X_val_scaled, y_val, X_scaler, y_scaler, \n",
    "                                  threshold=THRESHOLD, num_periods=NUM_PERIODS, fund_given=FUND_GIVEN, \n",
    "                                  num_months=NUM_MONTHS,incoming_loans_per_time_period=LOANS_PER_MONTH,\n",
    "                                  conf_quantile=CONF_QUANTILE, optimize_for=\"TODO\", \n",
    "                                  version=\"loan_amount_and_variance\", model_type=\"gp\", seed=SEED)\n",
    "\n",
    "print(\"Mean Total Profits:\")\n",
    "print(np.mean(np.sum(perf_gp[:,:,0], axis=1)))\n",
    "\n",
    "# Saving performances to pickle file and Loading performances from it\n",
    "filename = os.path.join(\"results\", \"perf_gp_MSE\")\n",
    "meta_info = [\"GP_MSE\"]\n",
    "performances = [perf_gp]\n",
    "store_performance_results(performances, meta_info, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
